{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b30050a",
   "metadata": {},
   "source": [
    "##### https://www.geeksforgeeks.org/python-create-video-using-multiple-images-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c7d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: ['000067_semseg.png', '000068_semseg.png', '000069_semseg.png', '000070_semseg.png', '000071_semseg.png', '000072_semseg.png', '000073_semseg.png', '000074_semseg.png', '000075_semseg.png', '000076_semseg.png', '000077_semseg.png', '000078_semseg.png', '000079_semseg.png', '000080_semseg.png', '000081_semseg.png', '000082_semseg.png', '000083_semseg.png', '000084_semseg.png', '000085_semseg.png', '000086_semseg.png', '000087_semseg.png', '000088_semseg.png', '000089_semseg.png', '000090_semseg.png', '000091_semseg.png', '000092_semseg.png', '000093_semseg.png', '000094_semseg.png', '000095_semseg.png', '000096_semseg.png', '000097_semseg.png', '000098_semseg.png', '000099_semseg.png', '000100_semseg.png', '000101_semseg.png', '000102_semseg.png', '000103_semseg.png', '000104_semseg.png', '000105_semseg.png', '000106_semseg.png', '000107_semseg.png', '000108_semseg.png', '000109_semseg.png', '000110_semseg.png', '000111_semseg.png', '000112_semseg.png', '000113_semseg.png', '000114_semseg.png', '000115_semseg.png', '000116_semseg.png', '000117_semseg.png', '000118_semseg.png', '000119_semseg.png', '000120_semseg.png', '000121_semseg.png', '000122_semseg.png', '000123_semseg.png', '000124_semseg.png', '000125_semseg.png', '000126_semseg.png', '000127_semseg.png', '000128_semseg.png', '000129_semseg.png', '000130_semseg.png', '000131_semseg.png', '000132_semseg.png', '000133_semseg.png', '000134_semseg.png', '000135_semseg.png', '000136_semseg.png', '000137_semseg.png', '000138_semseg.png', '000139_semseg.png', '000140_semseg.png', '000141_semseg.png', '000142_semseg.png', '000143_semseg.png', '000144_semseg.png', '000145_semseg.png', '000146_semseg.png', '000147_semseg.png', '000148_semseg.png', '000149_semseg.png', '000150_semseg.png', '000151_semseg.png', '000152_semseg.png', '000153_semseg.png', '000154_semseg.png', '000155_semseg.png', '000156_semseg.png', '000157_semseg.png', '000158_semseg.png', '000159_semseg.png', '000160_semseg.png', '000161_semseg.png', '000162_semseg.png', '000163_semseg.png', '000164_semseg.png', '000165_semseg.png', '000166_semseg.png', '000167_semseg.png', '000168_semseg.png', '000169_semseg.png', '000170_semseg.png', '000171_semseg.png', '000172_semseg.png', '000173_semseg.png', '000174_semseg.png', '000175_semseg.png', '000176_semseg.png', '000177_semseg.png', '000178_semseg.png', '000179_semseg.png', '000180_semseg.png', '000181_semseg.png', '000182_semseg.png', '000183_semseg.png', '000184_semseg.png', '000185_semseg.png', '000186_semseg.png', '000187_semseg.png', '000188_semseg.png', '000189_semseg.png', '000190_semseg.png', '000191_semseg.png', '000192_semseg.png', '000193_semseg.png', '000194_semseg.png', '000195_semseg.png', '000196_semseg.png', '000197_semseg.png', '000198_semseg.png', '000199_semseg.png', '000200_semseg.png', '000201_semseg.png', '000202_semseg.png', '000203_semseg.png', '000204_semseg.png', '000205_semseg.png', '000206_semseg.png', '000207_semseg.png', '000208_semseg.png', '000209_semseg.png', '000210_semseg.png', '000211_semseg.png', '000212_semseg.png', '000213_semseg.png', '000214_semseg.png', '000215_semseg.png', '000216_semseg.png', '000217_semseg.png', '000218_semseg.png', '000219_semseg.png', '000220_semseg.png', '000221_semseg.png', '000222_semseg.png', '000223_semseg.png', '000224_semseg.png', '000225_semseg.png', '000226_semseg.png', '000227_semseg.png', '000228_semseg.png', '000229_semseg.png', '000230_semseg.png', '000231_semseg.png', '000232_semseg.png', '000233_semseg.png', '000234_semseg.png', '000235_semseg.png', '000236_semseg.png', '000237_semseg.png', '000238_semseg.png', '000239_semseg.png', '000240_semseg.png', '000241_semseg.png', '000242_semseg.png', '000243_semseg.png', '000244_semseg.png', '000245_semseg.png']\n"
     ]
    }
   ],
   "source": [
    "import cv2, os, re\n",
    "\n",
    "image_folder = '/home/iot-class/Capstone/CARLA_tutorial/test_images/'\n",
    "video_name = 'real_video.mp4'\n",
    "\n",
    "images = sorted([img for img in os.listdir(image_folder) if \"pointcloud\" in img.lower()], key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "print(\"Images:\", images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9658df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set frame from the first image\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# Video writer to create .mp4 file\n",
    "fps = 1 / 0.05\n",
    "video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# Appending images to video\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "# Release the video file\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93b0a6",
   "metadata": {},
   "source": [
    "##### https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_video_file.py\n",
    "\n",
    "### Currently, facial recognition does not work well as the resolution of the videos and faces are not sufficient for this model.\n",
    "TODO: use newer YOLO model or another pipeline for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41be247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Open the input movie file\n",
    "input_movie = cv2.VideoCapture(\"real_video3.mp4\")\n",
    "length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Create an output movie file (make sure resolution/frame rate matches input video!)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_movie = cv2.VideoWriter('fr3test.mp4', fourcc, 20, (1600, 1200))\n",
    "\n",
    "# Load some sample pictures and learn how to recognize them.\n",
    "four_image = face_recognition.load_image_file(\"people/0004.png\")\n",
    "four_encoding = face_recognition.face_encodings(four_image)[0]\n",
    "\n",
    "nineteen_image = face_recognition.load_image_file(\"people/0019.png\")\n",
    "nineteen_encoding = face_recognition.face_encodings(nineteen_image)[0]\n",
    "\n",
    "twentyone_image = face_recognition.load_image_file(\"people/0021.png\")\n",
    "twentyone_encoding = face_recognition.face_encodings(twentyone_image)[0]\n",
    "\n",
    "known_faces = [\n",
    "    four_encoding,\n",
    "    nineteen_encoding,\n",
    "    twentyone_encoding\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "frame_number = 0\n",
    "face_count = Counter()\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = input_movie.read()\n",
    "    frame_number += 1\n",
    "\n",
    "    # Quit when the input video file ends\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # results = model(frame)\n",
    "\n",
    "    # for result in results:\n",
    "    #     for box in result.boxes:\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find all the faces and face encodings in the current frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame, model='cnn')\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        # See if the face is a match for the known face(s)\n",
    "        match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n",
    "\n",
    "        # If you had more than 2 faces, you could make this logic a lot prettier\n",
    "        # but I kept it simple for the demo\n",
    "        name = None\n",
    "        if match[0]:\n",
    "            name = \"four\"\n",
    "        elif match[1]:\n",
    "            name = \"nineteen\"\n",
    "        elif match[2]:\n",
    "            name = \"twentyone\"\n",
    "\n",
    "        face_names.append(name)\n",
    "        face_count[name] += 1\n",
    "\n",
    "    # Label the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Write the resulting image to the output video file\n",
    "    print(\"Writing frame {} / {}; {}\".format(frame_number, length, face_count))\n",
    "    output_movie.write(frame)\n",
    "\n",
    "# All done!\n",
    "input_movie.release()\n",
    "output_movie.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831ef736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'four': 25, None: 2})\n"
     ]
    }
   ],
   "source": [
    "print(face_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
